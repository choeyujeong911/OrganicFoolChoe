{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T05:57:21.508982Z",
     "start_time": "2025-09-18T05:57:21.504222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\" Fashion-MNIST 의류 이미지 분류 (올인원) - 확장 CNN + BatchNorm + Dropout - 학습/검증/테스트 + 혼동행렬 + 오분류 샘플 + 학습곡선 자동 저장\n",
    "- 결과물: ./outputs_fashion/\n",
    "\"\"\"\n",
    "import os, time, random, argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ],
   "id": "b1fdce55cd669489",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T05:57:22.711576Z",
     "start_time": "2025-09-18T05:57:22.705556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------- 공통 셋업 --------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    " random.seed(seed); np.random.seed(seed)\n",
    " torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    " torch.backends.cudnn.benchmark = False\n",
    " torch.backends.cudnn.deterministic = True\n",
    "\n",
    "CLASS_NAMES = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
    " \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
   ],
   "id": "26ccb9db880a75c7",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T05:57:23.923373Z",
     "start_time": "2025-09-18T05:57:23.918609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------- 데이터 --------------------\n",
    "def get_loaders(batch=64, num_workers=2):\n",
    " # 권장 통계: mean=0.2861, std=0.3530\n",
    " tf_train = transforms.Compose([\n",
    " transforms.RandomHorizontalFlip(p=0.5), # 약한 증강\n",
    " transforms.ToTensor(),\n",
    " transforms.Normalize((0.2861,), (0.3530,))\n",
    " ])\n",
    " tf_eval = transforms.Compose([\n",
    " transforms.ToTensor(),\n",
    " transforms.Normalize((0.2861,), (0.3530,))\n",
    " ])\n",
    " full_train = datasets.FashionMNIST(\"./data\", train=True, download=True,\n",
    "transform=tf_train)\n",
    " test_set = datasets.FashionMNIST(\"./data\", train=False, download=True,\n",
    "transform=tf_eval)\n",
    " train_len = 55000\n",
    " valid_len = len(full_train) - train_len\n",
    " train_set, valid_set = random_split(full_train, [train_len, valid_len],\n",
    " generator=torch.Generator().manual_seed(42))\n",
    " # valid에는 증강 없이 평가 변환 적용\n",
    " valid_set.dataset.transform = tf_eval\n",
    " train_loader = DataLoader(train_set, batch_size=batch, shuffle=True,\n",
    " num_workers=num_workers, pin_memory=True)\n",
    " valid_loader = DataLoader(valid_set, batch_size=batch, shuffle=False,\n",
    " num_workers=num_workers, pin_memory=True)\n",
    " test_loader = DataLoader(test_set, batch_size=batch, shuffle=False,\n",
    " num_workers=num_workers, pin_memory=True)\n",
    " return train_loader, valid_loader, test_loader"
   ],
   "id": "24afb2873efb06ae",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T05:57:25.856342Z",
     "start_time": "2025-09-18T05:57:25.851392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------- 모델 --------------------\n",
    "class Block(nn.Module):\n",
    "\n",
    " def __init__(self, in_c, out_c):\n",
    "  super().__init__()\n",
    "  self.conv1 = nn.Conv2d(in_c, out_c, 3, padding=1)\n",
    "  self.bn1 = nn.BatchNorm2d(out_c)\n",
    "  self.conv2 = nn.Conv2d(out_c, out_c, 3, padding=1)\n",
    "  self.bn2 = nn.BatchNorm2d(out_c)\n",
    "\n",
    " def forward(self, x):\n",
    "  x = F.relu(self.bn1(self.conv1(x)))\n",
    "  x = F.relu(self.bn2(self.conv2(x)))\n",
    "  return x"
   ],
   "id": "ee10f07d7417bd2d",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T05:57:27.199102Z",
     "start_time": "2025-09-18T05:57:27.193380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FashionCNN(nn.Module):\n",
    " \"\"\"\n",
    " 입력: (N,1,28,28)\n",
    " 출력: 10 클래스 logits\n",
    " \"\"\"\n",
    " def __init__(self, dropout=0.3):\n",
    "  super().__init__()\n",
    "  self.block1 = Block(1, 32) # 28x28\n",
    "  self.pool1 = nn.MaxPool2d(2,2) # 14x14\n",
    "  self.block2 = Block(32, 64) # 14x14\n",
    "  self.pool2 = nn.MaxPool2d(2,2) # 7x7\n",
    "  self.fc1 = nn.Linear(64*7*7, 256)\n",
    "  self.drop = nn.Dropout(dropout)\n",
    "  self.fc2 = nn.Linear(256, 10)\n",
    " def forward(self, x):\n",
    "  x = self.pool1(self.block1(x))\n",
    "  x = self.pool2(self.block2(x))\n",
    "  x = x.view(x.size(0), -1)\n",
    "  x = F.relu(self.fc1(x))\n",
    "  x = self.drop(x)\n",
    "  return self.fc2(x)"
   ],
   "id": "e61ca01a56c4a609",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T05:57:28.852118Z",
     "start_time": "2025-09-18T05:57:28.847150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------- 루프 --------------------\n",
    "def train_one_epoch(model, loader, opt, scaler, use_amp=False):\n",
    " model.train()\n",
    " crit = nn.CrossEntropyLoss()\n",
    " total, correct, loss_sum = 0, 0, 0.0\n",
    " for xb, yb in loader:\n",
    "  xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE,\n",
    "non_blocking=True)\n",
    "  opt.zero_grad(set_to_none=True)\n",
    "  if use_amp and DEVICE.type == \"cuda\":\n",
    "   with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "    logits = model(xb); loss = crit(logits, yb)\n",
    "   scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "  else:\n",
    "   logits = model(xb); loss = crit(logits, yb); loss.backward(); opt.step()\n",
    "  loss_sum += loss.item() * xb.size(0)\n",
    "  correct += (logits.argmax(1) == yb).sum().item()\n",
    "  total += xb.size(0)\n",
    " return loss_sum/total, correct/total\n"
   ],
   "id": "fe9f718befefba89",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T05:57:30.584502Z",
     "start_time": "2025-09-18T05:57:30.578916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    " model.eval()\n",
    " crit = nn.CrossEntropyLoss()\n",
    " total, correct, loss_sum = 0, 0, 0.0\n",
    " all_preds, all_targets = [], []\n",
    " for xb, yb in loader:\n",
    "  xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE,\n",
    "non_blocking=True)\n",
    "  logits = model(xb); loss = crit(logits, yb)\n",
    "  loss_sum += loss.item() * xb.size(0)\n",
    "  preds = logits.argmax(1)\n",
    "  correct += (preds == yb).sum().item()\n",
    "  total += xb.size(0)\n",
    "  all_preds.append(preds.cpu().numpy()); all_targets.append(yb.cpu().numpy())\n",
    "  return loss_sum/total, correct/total, np.concatenate(all_preds), np.concatenate(all_targets)"
   ],
   "id": "9b95809747826352",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T05:57:32.333433Z",
     "start_time": "2025-09-18T05:57:32.328824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------- 시각화 --------------------\n",
    "def plot_curves(hist, save_path):\n",
    " os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    " ep = range(1, len(hist[\"train_loss\"])+1)\n",
    " plt.figure(figsize=(10,4))\n",
    " plt.subplot(1,2,1)\n",
    " plt.plot(ep, hist[\"train_loss\"], label=\"Train Loss\")\n",
    " plt.plot(ep, hist[\"valid_loss\"], label=\"Valid Loss\")\n",
    " plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss Curve\"); plt.legend()\n",
    " plt.subplot(1,2,2)\n",
    " plt.plot(ep, hist[\"train_acc\"], label=\"Train Acc\")\n",
    " plt.plot(ep, hist[\"valid_acc\"], label=\"Valid Acc\")\n",
    " plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Accuracy Curve\"); plt.legend()\n",
    " plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.close()"
   ],
   "id": "9d7d6685f6be2295",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T05:57:33.725272Z",
     "start_time": "2025-09-18T05:57:33.718260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_confmat(y_true, y_pred, save_path):\n",
    " os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    " cm = confusion_matrix(y_true, y_pred)\n",
    " disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "display_labels=CLASS_NAMES)\n",
    " fig, ax = plt.subplots(figsize=(7,7))\n",
    " disp.plot(ax=ax, cmap=\"Blues\", xticks_rotation=45, colorbar=False,\n",
    "values_format=\"d\")\n",
    " plt.title(\"Confusion Matrix (Fashion-MNIST)\"); plt.tight_layout()\n",
    " plt.savefig(save_path, dpi=150); plt.close()\n",
    "\n",
    "def save_misclassified(y_true, y_pred, save_path, max_samples=25):\n",
    " os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    " mis_idx = np.where(y_true != y_pred)[0][:max_samples]\n",
    " if len(mis_idx)==0:\n",
    "  fig = plt.figure(figsize=(6,2)); plt.text(0.5,0.5,\"No misclassified samples.\", ha=\"center\", va=\"center\")\n",
    "  plt.axis(\"off\"); plt.savefig(save_path, dpi=150); plt.close();\n",
    "  return\n",
    "   # 정규화 되돌린 간단한 시각화\n",
    " inv = transforms.Normalize(mean=(-0.2861/0.3530,), std=(1/0.3530,))\n",
    " ds = datasets.FashionMNIST(\"./data\", train=False, download=True,\n",
    "                           transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                         transforms.Normalize((0.2861,), (0.3530,))]))\n",
    " cols=5; rows=int(np.ceil(len(mis_idx)/cols))\n",
    " plt.figure(figsize=(cols*2.2, rows*2.6))\n",
    " for i, idx in enumerate(mis_idx):\n",
    "  img, gt = ds[idx]\n",
    "  img = inv(img).squeeze().numpy()\n",
    "  pred = y_pred[idx]\n",
    "  plt.subplot(rows, cols, i+1)\n",
    "  plt.imshow(img, cmap=\"gray\")\n",
    "  plt.title(f\"GT:{CLASS_NAMES[gt]}\\nPred:{CLASS_NAMES[pred]}\", fontsize=9)\n",
    "  plt.axis(\"off\")\n",
    " plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.close()"
   ],
   "id": "3a2e2ca1c335fd19",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T05:57:35.871437Z",
     "start_time": "2025-09-18T05:57:35.849651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------- 메인 --------------------\n",
    "def run_train(args):\n",
    " set_seed(args.seed)\n",
    " os.makedirs(args.out_dir, exist_ok=True)\n",
    " print(f\"✅ Device: {DEVICE} | AMP: {'ON' if (args.amp and DEVICE.type=='cuda') else 'OFF'}\")\n",
    "\n",
    " tr_loader, va_loader, te_loader = get_loaders(args.batch_size, args.num_workers)\n",
    " model = FashionCNN(dropout=args.dropout).to(DEVICE)\n",
    " opt = Adam(model.parameters(), lr=args.lr)\n",
    " scaler = torch.amp.GradScaler(enabled=(args.amp and DEVICE.type=='cuda'))\n",
    "\n",
    " hist = {\"train_loss\":[], \"valid_loss\":[], \"train_acc\":[], \"valid_acc\":[]}\n",
    " best_acc, best_path = 0.0, os.path.join(args.out_dir, \"best_fashion_cnn.pt\")\n",
    "\n",
    " for epoch in range(1, args.epochs+1):\n",
    "  t0=time.time()\n",
    "  tr_loss, tr_acc = train_one_epoch(model, tr_loader, opt, scaler, use_amp=args.amp)\n",
    "  va_loss, va_acc, _, _ = evaluate(model, va_loader)\n",
    "  hist[\"train_loss\"].append(tr_loss); hist[\"valid_loss\"].append(va_loss)\n",
    "  hist[\"train_acc\"].append(tr_acc); hist[\"valid_acc\"].append(va_acc)\n",
    "  if va_acc > best_acc:\n",
    "   best_acc = va_acc; torch.save(model.state_dict(), best_path)\n",
    "  print(f\"[Epoch {epoch:02d}/{args.epochs}] \"\n",
    "        f\"Train loss {tr_loss:.4f}, acc {tr_acc:.4f} | \"\n",
    "        f\"Valid loss {va_loss:.4f}, acc {va_acc:.4f} | BestAcc {best_acc:.4f} | \"\n",
    "        f\"{time.time()-t0:.1f}s\")\n",
    "\n",
    " plot_curves(hist, os.path.join(args.out_dir, \"train_curve.png\"))\n",
    "\n",
    " # Test\n",
    " model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    " te_loss, te_acc, y_pred, y_true = evaluate(model, te_loader)\n",
    " print(f\"\\n Test: loss={te_loss:.4f}, acc={te_acc:.4f}\")\n",
    "\n",
    " plot_confmat(y_true, y_pred, os.path.join(args.out_dir, \"confusion_matrix.png\"))\n",
    " save_misclassified(y_true, y_pred, os.path.join(args.out_dir, \"misclassified_samples.png\"))\n",
    "\n",
    " print(f\"\\n 결과 저장 위치: {os.path.abspath(args.out_dir)}\")\n",
    " print(\" - 모델 가중치: best_fashion_cnn.pt\")\n",
    " print(\" - 학습곡선: train_curve.png\")\n",
    " print(\" - 혼동행렬: confusion_matrix.png\")\n",
    " print(\" - 오분류샘플: misclassified_samples.png\")"
   ],
   "id": "ff550b6d933bab87",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T06:04:44.362939Z",
     "start_time": "2025-09-18T05:57:38.696845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    " ap = argparse.ArgumentParser(\"Fashion-MNIST CNN (All-in-One)\")\n",
    " ap.add_argument(\"--epochs\", type=int, default=10)\n",
    " ap.add_argument(\"--batch-size\", type=int, default=64)\n",
    " ap.add_argument(\"--lr\", type=float, default=1e-3)\n",
    " ap.add_argument(\"--dropout\", type=float, default=0.3)\n",
    " ap.add_argument(\"--num-workers\", type=int, default=2)\n",
    " ap.add_argument(\"--amp\", action=\"store_true\")\n",
    " ap.add_argument(\"--seed\", type=int, default=42)\n",
    " ap.add_argument(\"--out-dir\", type=str, default=\"./outputs_fashion\")\n",
    " args, _ = ap.parse_known_args()\n",
    " run_train(args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    " main()"
   ],
   "id": "4c95d02bd0bbc742",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Device: cpu | AMP: OFF\n",
      "[Epoch 01/10] Train loss 0.3925, acc 0.8580 | Valid loss 0.3167, acc 0.8281 | BestAcc 0.8281 | 39.9s\n",
      "[Epoch 02/10] Train loss 0.2585, acc 0.9058 | Valid loss 0.2177, acc 0.9219 | BestAcc 0.9219 | 44.9s\n",
      "[Epoch 03/10] Train loss 0.2199, acc 0.9201 | Valid loss 0.3204, acc 0.8750 | BestAcc 0.9219 | 44.9s\n",
      "[Epoch 04/10] Train loss 0.1949, acc 0.9274 | Valid loss 0.2014, acc 0.9062 | BestAcc 0.9219 | 45.3s\n",
      "[Epoch 05/10] Train loss 0.1711, acc 0.9362 | Valid loss 0.2488, acc 0.9062 | BestAcc 0.9219 | 41.6s\n",
      "[Epoch 06/10] Train loss 0.1529, acc 0.9438 | Valid loss 0.1948, acc 0.9375 | BestAcc 0.9375 | 41.5s\n",
      "[Epoch 07/10] Train loss 0.1329, acc 0.9507 | Valid loss 0.3821, acc 0.8594 | BestAcc 0.9375 | 41.1s\n",
      "[Epoch 08/10] Train loss 0.1192, acc 0.9556 | Valid loss 0.2614, acc 0.9219 | BestAcc 0.9375 | 41.5s\n",
      "[Epoch 09/10] Train loss 0.1045, acc 0.9606 | Valid loss 0.4213, acc 0.8906 | BestAcc 0.9375 | 41.4s\n",
      "[Epoch 10/10] Train loss 0.0926, acc 0.9655 | Valid loss 0.2797, acc 0.9219 | BestAcc 0.9375 | 40.6s\n",
      "\n",
      " Test: loss=0.1992, acc=0.9062\n",
      "\n",
      " 결과 저장 위치: C:\\OrganicFoolChoe\\ch3\\outputs_fashion\n",
      " - 모델 가중치: best_fashion_cnn.pt\n",
      " - 학습곡선: train_curve.png\n",
      " - 혼동행렬: confusion_matrix.png\n",
      " - 오분류샘플: misclassified_samples.png\n"
     ]
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
